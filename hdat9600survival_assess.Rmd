---
title: "HDAT9600 Chapter Survival Modelling Assignment"
subtitle: "Submission deadline is 23:59pm Tuesday 11 August 2020 AEST"
author: "Murray Keogh"
date: "11/8/2020"
output: html_document
---

```{r setup, include=FALSE}
# leave this code here, but feel free to adjust the options or add some more
# see the knitr documentation for details
knitr::opts_chunk$set(echo = TRUE, fig.width=12, fig.height=12,warning=FALSE, message=FALSE)
```


## Instructions

This file is the R Markdown document in which you need to complete your HDAT9600 Survival Modelling assignment. This assignment is assessed and will count for 20% of the total course marks.

You should now complete the tasks described below, in the spaces provided. Don't hesitate to ask the course instructor for help (use OpenLearning environment to do that) --- but remember that these are **individual** assignments and thus what you submit should be your own work, and you need to both understand and be able to explain what you did in your solutions. The course instructor is happy to point you in the right direction and to make suggestions, but they won't, of course, complete your assignments for you!

Each task below attracts the indicated number of marks (out of a total of 20 marks for the assignment).


## Introduction

For the Survival Modelling assignment, we are going to analyse colon cancer survival data, available as a built-in dataset in the _survival_ package. These data include information from a clinical trial on the effectiveness of two different types of chemotherapy (levamisole and levamisole+5-fluorouracil) compared to controls (i.e. no chemotherapy treatment) on survival from stage B/C colon cancer. There are two rows per person in the dataset, one for cancer recurrence and one for death, indicated by the event type (`etype`) variable (`etype==1` corresponds to recurrence and `etype==2` to death). In the tasks below, you will focus on analysing death as an outcome.

As the _survival_ package is one of the core R packages, you don’t need to separately install it. To get started, you just need to load it into the workspace in R:

```{r data-setup}
library(survival)
library(dplyr)
library(survminer)
library(eha)
```


Familiarise yourself with the colon dataset and complete the following tasks by writing R code and commentary text where appropriate. All quantitative results must be generated by R code which you have included in this file. Results calculated by other means or by code not included in this file will not receive any marks.


## Task 1 (2 marks)

### Task 1.a

How many persons are there in the dataset?

```{r task-1-a}

#load the dataset
data(colon)

#check the information for dataset (comment out so no browser load)
#?colon

#look at first few rows
head(colon)

#check the data type of each column
sapply(colon, class)
glimpse(colon)

#number of unique id

length(unique(colon$id))

```

There are 929 people in the dataset. 

### Task 1.b

What categorical and continuous variables are there in the dataset that may be associated with a person’s survival?

The categorical variables that may be associated with a person's survival include rx, sex, obstruct, perfor, adhere, differ, extent, surg, and node4.  The continuous variables that may be associated with a person's survival include age and nodes.  

### Task 1.c

Provide frequencies for the categories of the categorical variables, and median and interquartile range (i.e. first quartile – third quartile) for the continuous variables.

```{r task-1-c}
#frequencies for categorical variables

table(colon$rx)
table(colon$sex)
table(colon$obstruct)
table(colon$perfor)
table(colon$adhere)
table(colon$differ)
table(colon$extent)
table(colon$surg)
table(colon$node4)


#median and IQR for the continuous variables

colon %>% summarize(median_age = median(age),
                    median_nodes = median(nodes,na.rm=TRUE),
                    IQR_age = IQR(age),
                    IQR_nodes = IQR(nodes,na.rm=TRUE))


```

### Task 1.d

What is the survival object?

The survival object for this analysis will be time and status. Time represents the days until event or censoring.  Status represents whether the individual experienced the event (recurrence or death) or whether the individual was censored. 


## Task 2 (2 marks)

In the following analyses, you will focus on analysing death as an outcome. You will thus first need to run the following code to select only the rows with death as an outcome: 

```{r task-2-data-setup}
colondeath <- colon[colon$etype == 2,]

```

### Task 2.a

Plot the overall Kaplan-Meier survival curve for the `colondeath` data.

```{r task-2-a}

km_estimate <- survfit( Surv(time = time,event = status)~1, data=colondeath)
ggsurvplot(km_estimate)

```

### Task 2.b

Report how many deaths were there during the follow-up and what was the median follow-up time until death.

```{r task-2-b}

#how many deaths during follow-up : status 1 means death so 452 deaths.

colondeath %>% group_by(status) %>% tally()

#median follow-up time is 774.5 days

colondeath %>% filter(status==1) %>% summarise(median = median(time))

```

### Task 2.c

Plot the Nelson-Aalen cumulative hazard function for the `colondeath` data.

```{r task-2-c}

# plotting Nelson-Aalen estimate
na_estimate <- survfit( Surv(time = time, event = status) ~ 1, data = colondeath) 
ggsurvplot(na_estimate, fun="cumhaz")

```


## Task 3 (3 marks)

### Task 3.a

Plot the Kaplan-Meier survival curves by all categorical variables in the data.

```{r task-3-a}

#plot by rx

km_estimate_rx <- survfit( Surv(time = time,event = status)~rx, data=colondeath)
ggsurvplot(km_estimate_rx)

#plot by sex

km_estimate_sex <- survfit( Surv(time = time,event = status)~sex, data=colondeath)
ggsurvplot(km_estimate_sex)

#plot by obstruct

km_estimate_obs <- survfit( Surv(time = time,event = status)~obstruct, data=colondeath)
ggsurvplot(km_estimate_obs)

#plot by perfor

km_estimate_perf <- survfit( Surv(time = time,event = status)~perfor, data=colondeath)
ggsurvplot(km_estimate_perf)

#plot by adhere

km_estimate_adh <- survfit( Surv(time = time,event = status)~adhere, data=colondeath)
ggsurvplot(km_estimate_adh)

#plot by differ

km_estimate_diff <- survfit( Surv(time = time,event = status)~differ, data=colondeath)
ggsurvplot(km_estimate_diff)

#plot by extent

km_estimate_ext <- survfit( Surv(time = time,event = status)~extent, data=colondeath)
ggsurvplot(km_estimate_ext)

#plot by surg

km_estimate_surg <- survfit( Surv(time = time,event = status)~surg, data=colondeath)
ggsurvplot(km_estimate_surg)

#plot by node4

km_estimate_node4 <- survfit( Surv(time = time,event = status)~node4, data=colondeath)
ggsurvplot(km_estimate_node4)

```

### Task 3.b

Report the number of deaths and the median survival times by categories of all categorical variables in the data (for example in a format of a table).

```{r task-3-b}

#group by each of the categorical variables, calculating the number of deaths and median survival time for each category. 

colondeath %>% group_by(rx) %>% summarize(deaths = sum(status),
                    median_survival_time = median(time,na.rm=TRUE))



colondeath %>% group_by(sex) %>% summarize(deaths = sum(status),
                    median_survival_time = median(time,na.rm=TRUE))



colondeath %>% group_by(obstruct) %>% summarize(deaths = sum(status),
                    median_survival_time = median(time,na.rm=TRUE))



colondeath %>% group_by(perfor) %>% summarize(deaths = sum(status),
                    median_survival_time = median(time,na.rm=TRUE))



colondeath %>% group_by(adhere) %>% summarize(deaths = sum(status),
                    median_survival_time = median(time,na.rm=TRUE))



colondeath %>% group_by(differ) %>% summarize(deaths = sum(status),
                    median_survival_time = median(time,na.rm=TRUE))



colondeath %>% group_by(extent) %>% summarize(deaths = sum(status),
                    median_survival_time = median(time,na.rm=TRUE))



colondeath %>% group_by(surg) %>% summarize(deaths = sum(status),
                    median_survival_time = median(time,na.rm=TRUE))



colondeath %>% group_by(node4) %>% summarize(deaths = sum(status),
                    median_survival_time = median(time,na.rm=TRUE))

```

### Task 3.c

Carry out the log-rank tests for differences in survival experience by the categorical variables and interpret the results.

```{r task-3-c}

#using standard log-rank tests for differences since data is not left-truncated.

#rx log-rank test : significant
rx_diff <- survdiff( Surv(time = time,event = status)~rx, data=colondeath)
rx_diff

#sex log-rank test : not significant
sex_diff <- survdiff( Surv(time = time,event = status)~sex, data=colondeath)
sex_diff

#obstruct log-rank test : significant
obs_diff <- survdiff( Surv(time = time,event = status)~obstruct, data=colondeath)
obs_diff

#perfor log-rank test : not significant
perf_diff <- survdiff( Surv(time = time,event = status)~perfor, data=colondeath)
perf_diff

#adhere log-rank test : significant
adh_diff <- survdiff( Surv(time = time,event = status)~adhere, data=colondeath)
adh_diff

#differ log-rank test : significant
diff_diff <- survdiff( Surv(time = time,event = status)~differ, data=colondeath)
diff_diff

#extent log-rank test : significant
ext_diff <- survdiff( Surv(time = time,event = status)~extent, data=colondeath)
ext_diff

#surg log-rank test : significant
surg_diff <- survdiff( Surv(time = time,event = status)~surg, data=colondeath)
surg_diff

#node4 log-rank test : significant
node4_diff <- survdiff( Surv(time = time,event = status)~node4, data=colondeath)
node4_diff

```
From the log-rank test output above, I observe that rx, obstruct, adhere, differ, extent, surg, and node4 are all statistically significant.  I also observe that both sex and perfor are not statistically significant.  We reject the null hypothesis that there is no difference between the groups for the statistically significant variables, and conclude that there is statistical evidence that survival time is different.  


## Task 4 (3 marks)

### Task 4.a

Fit univariable Cox models for all categorical and continuous variables in the data [Note: there is both a continuous and a categorical variable for the number of positive lymph nodes with detectable cancer – you can just use the categorical variable in your analysis]. Interpret the results.

```{r task-4-a}

# cox model with rx as only covariate
cox_rx <- coxph(Surv(time = time,event = status)~rx, data=colondeath) 
summary(cox_rx)

# cox model with sex as only covariate
cox_sex <- coxph(Surv(time = time,event = status)~sex, data=colondeath) 
summary(cox_sex)

# cox model with age as only covariate
cox_age <- coxph(Surv(time = time,event = status)~age, data=colondeath) 
summary(cox_age)

# cox model with obstruct as only covariate
cox_obs <- coxph(Surv(time = time,event = status)~obstruct, data=colondeath) 
summary(cox_obs)

# cox model with perfor as only covariate
cox_perf <- coxph(Surv(time = time,event = status)~perfor, data=colondeath) 
summary(cox_perf)

# cox model with adhere as only covariate
cox_adh <- coxph(Surv(time = time,event = status)~adhere, data=colondeath) 
summary(cox_adh)

# cox model with differ as only covariate
cox_diff <- coxph(Surv(time = time,event = status)~differ, data=colondeath) 
summary(cox_diff)

# cox model with extent as only covariate
cox_ext <- coxph(Surv(time = time,event = status)~extent, data=colondeath) 
summary(cox_ext)

# cox model with surg as only covariate
cox_surg <- coxph(Surv(time = time,event = status)~surg, data=colondeath) 
summary(cox_surg)

# cox model with node4 as only covariate
cox_node4 <- coxph(Surv(time = time,event = status)~node4, data=colondeath) 
summary(cox_node4)


```

I observe the same p-values for the categorical variables when comparing the above univariable Cox models logrank test output to the log-rank tests computed in Task 3c.  Further, the only continuous variable, age, that I fit a univariable Cox model was not statistically significant for any of the three statistical tests.  

### Task 4.b

Fit a multivariable Cox model with all the variables that were significant in the univariable Cox models. Interpret the results. Are all the variables that were significant in the univariable models still significant in the multivariable model?

```{r task-4-b}
# fitting multivariable Cox model with rx, obstruct, adhere, differ, extent, surg, and node4 covariates.
cox_mv <- coxph(Surv(time = time,event = status)~ rx + obstruct + adhere + differ + extent + surg + node4, data=colondeath) 
summary(cox_mv)

```

From above, I observe that adhere is not statistically significant in the multivariable Cox model. I also observe that R automatically interprets the rx variable as a factor, and also that the rxLev+5Fu level is statistically significant, whereas the rxLev level is not statistically significant when compared with the base level of Obs. 

### Task 4.c

Compare the multivariable model that you fitted in task 4.b and the multivariable model with all the categorical and continuous variables (for which you fitted univariable models in task 4a) using the likelihood ratio test. Interpret the results. What are the AICs for the two models (show how you calculated them) and how are they interpreted?

```{r task-4-c}

#fit model with all predictors
cox_mv_all <- coxph(Surv(time = time,event = status)~rx + sex + age+ obstruct + perfor + adhere + differ + extent + surg + node4, data=colondeath) 
summary(cox_mv_all)

#perfrom likelihood ratio test
print(anova(cox_mv, cox_mv_all))


#manual AIC calculation using the log likelihood and degrees of freedom
cox_mv_aic <- 2*8 - 2*(-2781.6)
cox_mv_all_aic <- 2*11 - 2*(-2779.7)

cox_mv_aic
cox_mv_all_aic

#using R to calculate the AIC (will use this method in future)

extractAIC(cox_mv)
extractAIC(cox_mv_all)

```

From the ANOVA output, I observe a p-value of .29, and I can conclude that I fail to reject the null hypothesis. I also observe that the AIC for the simpler model is less than the AIC for the more complex model, and a lower AIC is preferred.  As a result, I would choose to use the simpler model when comparing these two.    

### Task 4.d

Compare the multivariable model that you fitted in task 4.b and the multivariable model with only the significant variables (in that multivariable model) included in the model using the likelihood ratio test. Interpret the results. What are the AICs for the two models (show how you calculated them) and how are they interpreted?

```{r task-4-d}

#fit multivariable Cox model, removing adhere from model in 4b
cox_mv_subset <- coxph(Surv(time = time,event = status) ~ rx + obstruct + differ + extent + surg + node4, data=colondeath) 
summary(cox_mv_subset)

#perfrom likelihood ratio test
print(anova(cox_mv,cox_mv_subset))

#calculate the AIC

extractAIC(cox_mv)
extractAIC(cox_mv_subset)



```

From the ANOVA output, I observe a p-value of .19, and I can conclude that I fail to reject the null hypothesis. I also observe that the AIC for the subset model is less than the AIC for the larger model, and a lower AIC is preferred.  As a result, I would choose to use the subsetted model when comparing these two.   


## Task 5 (2.5 marks)

### Task 5.a

Check whether the proportional hazards assumptions hold for the variables included in the multivariable model that only includes significant variables (i.e. the latter model in task 4.d). Interpret the results.

```{r task-5-a}
# testing for proportional hazards assumption using cox.zph()
prop_mv_subset <- cox.zph(cox_mv_subset)

#output
prop_mv_subset

#plots
ggcoxzph(prop_mv_subset)

```

From the output, I conclude that obstruct, differ, extent, and node4 all have statistically significant p-values. This means that the proportional hazards assumption is violated for these four variables.  Also, I see that the GLOBAL p-value is .00013 which means the entire model also violates the proportional hazards assumption. 

### Task 5.b

You would like to obtain hazard ratios for all of the variables in the model, and thus you choose to address the violations of the proportional hazards assumption by including time x covariate interactions in the model for the variables that violated the proportional hazards assumption.

Take a look at the survival curves stratified by the variables that violated the proportional hazards assumption [Note: you have already plotted these survival curves in task 3.a]. Choose a follow-up time point around which to split the follow-up time to fit two Cox models to attempt to resolve the violation, and split the dataset into two time intervals around your chosen time point.

```{r task-5-b}
# From visual inspection of obstruct, differ, extent and node4 survival curves, I decided to split at time 1800

# splitting the colondeath dataset to two time intervals around time 1800
colondeath_split <- survSplit(Surv(time = time,event = status) ~ ., data = colondeath, cut=c(1800), episode= "tgroup", id="id2")
head(colondeath_split)

```


## Task 6 (2.5 marks)

### Task 6.a

Fit the multivariable Cox model with time x covariate interactions for the variables that violated the proportional hazards assumption using the dataset you created in task 5.b in this assignment. Interpret the results [Hint: if you have chosen the follow-up cut-off point wisely, you should see significant associations in at least one time interval].

```{r task-6-a}
# fitting Cox multivariable model to the new split dataset
cox_mv_split <- coxph(Surv(time = time,event = status) ~ rx + obstruct:strata(tgroup) + differ:strata(tgroup)+ extent:strata(tgroup) + surg + node4:strata(tgroup), data = colondeath_split) 
summary(cox_mv_split)

```

From the output above, there appears to be statistical significance for all four stratified variables in the first time period.  Obstruct and differ are statistically significant at the 95% level, and extent and node4 are statistically significant at the 99.9% level. 

### Task 6.b

Check whether the proportional hazards assumptions now hold for the multivariable Cox model with time x covariate interactions. Interpret the results.

```{r task-6-b}
# testing for proportional hazards assumption using cox.zph() and split model
prop_mv_split <- cox.zph(cox_mv_split)
prop_mv_split

```

The GLOBAL p-value is .00089 which means the model still violates the proportional hazards assumption.  From the output above, I do observe that the extent and node4 stratified variables now have a higher p-value and now pass the assumption. However, obstruct and differ still violate the proportional hazards assumption as evidenced by low p-values. 


## Task 7 (2.5 marks)

### Task7.a

Fit and plot the multivariable model that only includes significant variables (i.e. the latter model in task 4.d) using a parametric Weibull baseline hazard distribution.

```{r task-7-a}
#fitting a Weibull baseline distribution
w_mv <- phreg(Surv(time = time,event = status) ~ rx + obstruct + differ + extent + surg + node4, data=colondeath)
w_mv

#plot the outputs
plot(w_mv)

```

### Task 7.b

Fit and plot the same multivariable model that only includes significant variables using a parametric piecewise constant (exponential) baseline hazard distribution. Use the same follow-up time cut-off as for the Cox model in task 6.a.

```{r task-7-b}
# fitting a piecewise constant hazards distribution with cut-off at 1800
pch_mv <- phreg( Surv(time = time, event = status) ~ rx + obstruct + differ + extent + surg + node4,data=colondeath, dist = "pch", cuts = c(1800))
pch_mv

#plot the outputs
plot(pch_mv)

```
I observe a change in the plots at the cutoff point of 1800.  The hazard and survivor functions change here as the stratified variables between the two time periods change the function. 

## Task 8 (2.5 marks)

### Task 8.a

Compare the model fit of the two models you ran in task 7, by obtaining their maximised log likelihoods. Interpret the results. Because these two models are not nested, a more appropriate way to compare the model fit is by comparing the AICs. Which model has the lowest AIC?

```{r task-8-a}

#compare maximum log likelihoods

print(w_mv$loglik[2])
print(pch_mv$loglik[2])

#Compare AIC
extractAIC(w_mv)
extractAIC(pch_mv)

```

The maximized log-likelihood is larger for the piecewise hazard distribution, -3955 compared to -3962 for the weibull hazard distribution.  The AIC is also lower for the piecewise when compared to the weibull. Since a larger maximized log-likelihood value and lower AIC is preferred, the piecewise model is best.  

### Task 8.b

Further compare the model fit by plotting the cumulative hazard functions of these two parametric models in the same graph with the cumulative hazard function of the Cox model (including the same variables). Interpret the results.

```{r task-8-b}
# Fitting a Cox model using the same Y response variable and coxreg function required by the check.dist function
cox_mv <- coxreg(Surv(time = time, event = status) ~ rx + obstruct + differ + extent + surg + node4,data=colondeath)

check.dist(cox_mv, w_mv)
check.dist(cox_mv,pch_mv)

```

Comparing the two plots above, I observe that the piecewise model fits best. This is especially evident at higher durations, especially after the cut-off point of 1800.  The weibull model is not flexible enough, especially as the duration gets longer.  

## Save, knit and submit

**Reminder**: don't forget to save this file, to knit it to check that everything works, and then submit via the drop box in Openlearning.

## Submit your assignment

When you have finished, and are satisfied with your assignment solutions, and this file knits without errors and the output looks the way you want, then you should submit via the drop box in Openlearning.

### Problems?

If you encounter problems with any part of the process described above, please contact the course instructor via OpenLearning as soon as possible so that the issues can be resolved in good time, and well before the assignment is due.
